### 4.Kubernetes - Persistent Volume

#### 安装[Centos7安装配置NFS服务和挂载](https://www.cnblogs.com/lixiuran/p/7117000.html)

- 一、安装 NFS 服务器所需的软件包：

  ```
  yum install -y nfs-utils
  ```

- 二、编辑exports文件，添加从机

  ```
  vim /etc/exports
  /home/nfs/ 192.168.248.0/24(rw,sync,fsid=0)
  ```

  ```
  [root@hub home]# mkdir nfs
  [root@hub home]# chmod -R 777 nfs/
  [root@hub home]# chown nfsnobody 
  nfs/     vagrant/ 
  [root@hub home]# chown -R nfsnobody:nfsnobody nfs/
  ```

  同192.168.248.0/24一个网络号的主机可以挂载NFS服务器上的/home/nfs/目录到自己的文件系统中

  rw表示可读写；sync表示同步写，fsid=0表示将/data找个目录包装成根目录

- 三、启动nfs服务

  先为rpcbind和nfs做开机启动：(必须先启动rpcbind服务)

  ```
  systemctl enable rpcbind.service
  systemctl enable nfs-server.service
  ```

  然后分别启动rpcbind和nfs服务：

  ```
  systemctl start rpcbind.service
  systemctl start nfs-server.service
  ```

  确认NFS服务器启动成功：

  ```
  rpcinfo -p
  ```

  检查 NFS 服务器是否挂载我们想共享的目录 /home/nfs/：

  ```
  exportfs -r
  ```

  使配置生效

  ```
  exportfs
  ```

  可以查看到已经ok

  ```
  /home/nfs 192.168.248.0/24
  ```

- 四、在从机上安装NFS 客户端

  首先是安裝nfs，同上，然后启动rpcbind服务

  先为rpcbind做开机启动：

  ```
  systemctl enable rpcbind.service
  ```

  然后启动rpcbind服务：

  ```
  systemctl start rpcbind.service
  ```

  注意：客户端不需要启动nfs服务

  检查 NFS 服务器端是否有目录共享：showmount -e nfs服务器的IP

  ```
  showmount -e 192.168.248.208
  Export list for 192.168.248.208:
  /home/nfs 192.168.248.0/24
  ```

  在从机上使用 mount 挂载服务器端的目录/home/nfs到客户端某个目录下：

  ```
  cd /home && mkdir nfs
  mount -t nfs 192.168.248.208:/home/nfs /home/nfs
  ```

  df -h 查看是否挂载成功。

  http://blog.csdn.net/taiyang1987912/article/details/41696319

  http://www.linuxidc.com/Linux/2015-05/117378.htm

  常用命令

  ```
  vi /etc/exports
  systemctl restart rpcbind.service && systemctl restart nfs-server.service
  rpcinfo -p
  exportfs
  showmount -e 192.168.33.100
  ```

  

#### 概念

##### PersistentVolume（PV）

```
是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、
iSCSI 或特定于云供应商的存储系统
```

创建01-pv.yaml

```
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv1
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: nfs
  nfs:
    path: /home/nfs
    server: 192.168.33.100
```

```
[root@k8s-master01 pv]# kubectl get pv
NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
nfspv1   5Gi        RWO            Recycle          Available           nfs                     25s
[root@k8s-master01 pv]# 
```

创建02-pv.yaml 

```
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv2
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadOnlyMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: nfs
  nfs:
    path: /home/nfs1
    server: 192.168.33.100
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv3
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadOnlyMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: nfs
  nfs:
    path: /home/nfs2
    server: 192.168.33.100
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv4
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadOnlyMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: nfs
  nfs:
    path: /home/nfs3
    server: 192.168.33.100
```

```
[root@k8s-master01 pv]# kubectl get pv
NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
nfspv1   5Gi        RWO            Recycle          Available           nfs                     38m
nfspv2   5Gi        ROX            Retain           Available           nfs                     49s
nfspv3   5Gi        ROX            Retain           Available           nfs                     49s
nfspv4   1Gi        ROX            Retain           Available           nfs                     49s
```



- ###### Kuberntes 中无法删除 PV 的解决方法

  ```
  $ kubectl patch pv pv-nfs-gysl -p '{"metadata":{"finalizers":null}}'
  persistentvolume/pv-nfs-gysl patched
  $ kubectl get pv
  No resources found.
  ```

  

##### PersistentVolumeClaim （PVC）

```
是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源
（CPU 和内存）。声明可以请求特定的大小和访问模式（例如，可以以读/写一次或 只读多次模式挂载）
```



##### **创建服务并使用** PVC

```
apiVersion: v1 
kind: Service 
metadata: 
  name: nginx 
  labels: 
    app: nginx 
spec: 
  ports: 
  - port: 80 
    name: web 
  clusterIP: None 
  selector: 
    app: nginx
--- 
apiVersion: apps/v1 
kind: StatefulSet 
metadata: 
  name: web 
spec: 
  selector: 
    matchLabels: 
      app: nginx 
  serviceName: "nginx" 
  replicas: 3 
  template: 
    metadata: 
      labels: 
        app: nginx 
    spec: 
      containers: 
      - name: nginx 
        image: k8s.gcr.io/nginx-slim:0.8 
        ports: 
        - containerPort: 80 
          name: web 
        volumeMounts: 
        - name: www 
          mountPath: /usr/share/nginx/html 
  volumeClaimTemplates: 
    - metadata: 
        name: www 
      spec: 
        accessModes: [ "ReadWriteOnce" ] 
        storageClassName: "nfs" 
        resources: 
          requests: 
            storage: 1Gi
```







